from generate_json_solvers import GenerateJSONSolvers
from solver_generators.word_comparisons import WordComparison
from definitions import ROOT_DIR
from collections import defaultdict
from datetime import datetime

import os
import json

from typing import List

OUTPUT_CONTENT = """
# Solver Scores
## Explanation
The solvers are stored in JSON files under solvers/json/. These files contain
all the guesses the solver will do depending on the matches thus far. This
file is generated by `generate_json_solvers.py` to score each solver. These
scores can be used to compare solvers and see improvements as we write new
ones.

## Scores
| Solver | Mode | 1 Guess | 2 Guesses | 3 Guesses | 4 Guesses | 5 Guesses | 6 Guesses | Remaining | Percentage 6 Guesses or Fewer |
|--------|------|---------|-----------|-----------|-----------|-----------|-----------|-----------|-------------------------------|
{rows}
"""
SOLVER_ROW_TEMPLATE = "{solver} | {mode} | {counts} | {percentage}"

class CalculateWordSplits(object):
    README_FILEPATH = "reports/report_output/word_splits.md"
    JSON_FILEPATH = "reports/report_output/word_splits.json"
    JSON_DETAILS_FILEPATH = "reports/report_output/word_splits_breakdown_{side}.json"

    def _get_top_n_words(self, split_count_words: dict, n: int, descending=True) -> List[str]:
        """
        Return the top N words
        """
        top_words = []
        for key, val in sorted(split_count_words.items(), reverse=descending):
            for word in val:
                top_words.append(word)
                if len(top_words) == n:
                    return top_words

    def run(self):
        """
        Loop over all the words and determine how many buckets each word splits the list into
        """
        split_count_words = defaultdict(list)

        # Loop over the words and store how much they split the options
        full_word_list = GenerateJSONSolvers.load_word_list()
        for index, guess in enumerate(full_word_list):
            split_count = len(WordComparison.split_into_pattern_match_groups(guess=guess, word_list=full_word_list))
            split_count_words[split_count].append(guess)

            if index % 100 == 0:
                print("%s: Index %d out of %d" % (datetime.now(), index, len(full_word_list)))

        # Store the JSON information for the splits
        with open(os.path.join(ROOT_DIR, self.JSON_FILEPATH), 'w') as f:
            json_output = {"{:03d}".format(key): val for key, val in split_count_words.items()}
            json.dump(json_output, f, sort_keys=True, indent=2)

        return None  # Exit early

        # Get the top and bottom 5
        extremes = {
            'top': self._get_top_n_words(split_count_words, 5, True),
            'bottom': self._get_top_n_words(split_count_words, 5, False)
        }
        for side, guesses in extremes.items():
            words_data = []
            for guess in guesses:
                word_data = {}
                split_data = WordComparison.split_into_pattern_match_groups(guess=guess, word_list=full_word_list)

                # Convert each split into a count and example
                #for

        # Save the documentation
        #output = OUTPUT_CONTENT.format(rows="\n".join(solver_rows))
        #with open(os.path.join(ROOT_DIR, self.OUTPUT_FILEPATH), 'w') as f:
        #    f.write(output)

if __name__ == '__main__':
    CalculateWordSplits().run()
